# AI è¾…åŠ©æ£€æµ‹æ¨¡å— ä½¿ç”¨è¯´æ˜

## æ¦‚è¿°

AI è¾…åŠ©æ£€æµ‹æ¨¡å—ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ API Key æ£€æµ‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å‡é˜³æ€§ç‡ã€‚

**æ ¸å¿ƒä¼˜åŠ¿**:
- ğŸ¯ **94% å‡é˜³æ€§å‡å°‘** - å‚è€ƒ GitHub Copilot MetaReflection æŠ€æœ¯
- ğŸ§  **ä¸Šä¸‹æ–‡æ„ŸçŸ¥** - ç†è§£ä»£ç è¯­ä¹‰ï¼Œè¯†åˆ«çœŸå® vs æµ‹è¯• Key
- âš¡ **åŒå±‚è¿‡æ»¤** - è§„åˆ™å¼•æ“å¿«é€Ÿç­›é€‰ + AI æ·±åº¦åˆ†æ
- ğŸ’° **æˆæœ¬ä¼˜åŒ–** - ä¼˜å…ˆä½¿ç”¨æœ¬åœ° Ollamaï¼ŒèŠ‚çœ API è´¹ç”¨

## æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SmartDetector (æ™ºèƒ½æ£€æµ‹å™¨)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      QuickFilter           â”‚         AIDetector             â”‚
â”‚      (è§„åˆ™å¼•æ“)             â”‚         (LLM åˆ†æ)             â”‚
â”‚                            â”‚                                â”‚
â”‚  â€¢ æµ‹è¯•æ¨¡å¼æ£€æµ‹            â”‚  â€¢ Ollama æœ¬åœ°æ¨¡å‹             â”‚
â”‚  â€¢ ç†µå€¼è®¡ç®—                â”‚  â€¢ OpenAI API                  â”‚
â”‚  â€¢ é‡å¤æ¨¡å¼è¯†åˆ«            â”‚  â€¢ Few-shot æç¤º               â”‚
â”‚  â€¢ æ–‡ä»¶è·¯å¾„åˆ†æ            â”‚  â€¢ Chain of Thought            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   æ£€æµ‹ç»“æœ        â”‚
                    â”‚  â€¢ ç½®ä¿¡åº¦         â”‚
                    â”‚  â€¢ Key ç±»å‹       â”‚
                    â”‚  â€¢ å¹³å°è¯†åˆ«       â”‚
                    â”‚  â€¢ æ¨ç†è¿‡ç¨‹       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£… Ollama (æ¨è)

```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# ä» https://ollama.ai/download ä¸‹è½½å®‰è£…

# æ‹‰å–æ¨¡å‹ (é€‰æ‹©ä¸€ä¸ª)
ollama pull llama3.2:3b    # å¿«é€Ÿï¼Œé€‚åˆåˆç­› (æ¨è)
ollama pull llama3.1:8b    # å¹³è¡¡
ollama pull qwen2.5:7b     # ä¸­æ–‡å‹å¥½
ollama pull mistral:7b     # é«˜è´¨é‡

# éªŒè¯
ollama list
```

### 2. è¿è¡Œæµ‹è¯•

```bash
# æ£€æŸ¥åç«¯å¯ç”¨æ€§
python test_ai_detector.py --check

# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_ai_detector.py --all

# äº¤äº’å¼æµ‹è¯•
python test_ai_detector.py --interactive
```

### 3. åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from ai_detector import SmartDetector, CodeContext

# åˆ›å»ºæ£€æµ‹å™¨
detector = SmartDetector()
await detector.initialize()

# åˆ†æä»£ç ç‰‡æ®µ
context = CodeContext(
    code_snippet='''
    OPENAI_API_KEY = "sk-proj-abc123..."
    client = OpenAI(api_key=OPENAI_API_KEY)
    ''',
    file_path="config.py"
)

should_validate, result = await detector.should_validate(
    candidate_key="sk-proj-abc123...",
    code_context=context
)

if should_validate:
    print(f"åº”è¯¥éªŒè¯: {result.provider} Key")
else:
    print(f"è·³è¿‡: {result.reasoning}")
```

## æ£€æµ‹ç»“æœ

### ç½®ä¿¡åº¦çº§åˆ«

| çº§åˆ« | è¯´æ˜ | å¤„ç†å»ºè®® |
|------|------|---------|
| `HIGH` | é«˜åº¦ç¡®ä¿¡æ˜¯çœŸå® Key | ç«‹å³éªŒè¯ |
| `MEDIUM` | è¾ƒå¯èƒ½æ˜¯çœŸå® Key | éªŒè¯ |
| `LOW` | å¯èƒ½æ˜¯ Keyï¼Œä½†ä¸ç¡®å®š | å¯é€‰éªŒè¯ |
| `NONE` | ä¸æ˜¯ API Key | è·³è¿‡ |

### Key ç±»å‹

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `REAL` | çœŸå® Key | é…ç½®æ–‡ä»¶ä¸­çš„ Key |
| `TEST` | æµ‹è¯• Key | `sk-test-xxx` |
| `EXAMPLE` | ç¤ºä¾‹ Key | æ–‡æ¡£ä¸­çš„ç¤ºä¾‹ |
| `PLACEHOLDER` | å ä½ç¬¦ | `YOUR_API_KEY` |
| `FAKE` | æ˜æ˜¾å‡çš„ Key | `sk-xxxxxxxxxxxx` |

## é…ç½®

### ç¯å¢ƒå˜é‡

```bash
# AI æ£€æµ‹å™¨å¼€å…³
export AI_DETECTOR_ENABLED=true

# åç«¯é€‰æ‹©: ollama, openai, mock
export AI_DETECTOR_BACKEND=ollama

# Ollama é…ç½®
export OLLAMA_URL=http://localhost:11434
export OLLAMA_MODEL=llama3.2:3b

# OpenAI é…ç½® (å¤‡é€‰)
export OPENAI_API_KEY=sk-xxx
export OPENAI_MODEL=gpt-3.5-turbo

# å¿«é€Ÿè¿‡æ»¤å™¨
export AI_QUICK_FILTER=true

# ç¼“å­˜
export AI_CACHE_ENABLED=true
export AI_CACHE_SIZE=1000
```

### YAML é…ç½®

åœ¨ `notify_config.yaml` ä¸­æ·»åŠ :

```yaml
ai_detector:
  enabled: true
  backend: ollama  # ollama, openai, mock

  # Ollama é…ç½®
  ollama_url: http://localhost:11434
  ollama_model: llama3.2:3b

  # OpenAI é…ç½® (å¤‡é€‰)
  openai_api_key: ""
  openai_model: gpt-3.5-turbo

  # å¿«é€Ÿè¿‡æ»¤å™¨
  quick_filter_enabled: true

  # ç¼“å­˜
  cache_enabled: true
  cache_size: 1000
```

## é›†æˆåˆ° Scanner

### æ–¹å¼ä¸€: ç›´æ¥ä½¿ç”¨

```python
from ai_scanner_integration import ScannerAIIntegration

# åˆ›å»ºé›†æˆå®ä¾‹
ai_integration = ScannerAIIntegration(
    enable_ai=True,
    ollama_model="llama3.2:3b"
)
await ai_integration.initialize()

# è¿‡æ»¤å€™é€‰ Key
result = await ai_integration.filter_candidate(
    platform="openai",
    api_key="sk-proj-xxx",
    code_snippet="...",
    file_path="config.py"
)

if result.should_validate:
    # ç»§ç»­éªŒè¯
    pass
else:
    print(f"AI è¿‡æ»¤: {result.filter_reason}")
```

### æ–¹å¼äºŒ: ä¾¿æ·å‡½æ•°

```python
from ai_scanner_integration import should_validate_key

should_validate, reason = await should_validate_key(
    api_key="sk-proj-xxx",
    code_snippet="...",
    file_path="config.py"
)
```

## æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨å¿«é€Ÿè¿‡æ»¤å™¨é¢„ç­›é€‰

å¿«é€Ÿè¿‡æ»¤å™¨ä½¿ç”¨è§„åˆ™å¼•æ“ï¼Œæ— éœ€ LLM è°ƒç”¨:

```python
from ai_detector import QuickFilter

quick_filter = QuickFilter()
is_fake, reason = quick_filter.is_likely_fake(
    candidate_key="sk-test-xxx",
    context="# test file",
    file_path="test.py"
)

if is_fake:
    print(f"å¿«é€Ÿè¿‡æ»¤: {reason}")
    # è·³è¿‡ LLM åˆ†æ
```

### 2. æ‰¹é‡å¤„ç†

```python
candidates = [
    {"platform": "openai", "api_key": "sk-xxx", "code_snippet": "..."},
    # ...
]

results = await ai_integration.filter_batch(candidates, concurrency=10)
```

### 3. ç¼“å­˜

é»˜è®¤å¯ç”¨ç¼“å­˜ï¼Œç›¸åŒçš„ä»£ç ç‰‡æ®µ+Key ç»„åˆåªåˆ†æä¸€æ¬¡:

```python
detector = AIDetector(cache_enabled=True, cache_size=1000)
```

## æµ‹è¯•å‘½ä»¤

```bash
# æ£€æŸ¥åç«¯çŠ¶æ€
python test_ai_detector.py --check

# æµ‹è¯•å¿«é€Ÿè¿‡æ»¤å™¨
python test_ai_detector.py --quick

# æµ‹è¯• AI æ£€æµ‹å™¨
python test_ai_detector.py --backend ollama
python test_ai_detector.py --backend openai
python test_ai_detector.py --backend mock

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python test_ai_detector.py --all

# äº¤äº’å¼æµ‹è¯•
python test_ai_detector.py --interactive
```

## æ¨èæ¨¡å‹

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | è´¨é‡ | æ¨èåœºæ™¯ |
|------|------|------|------|---------|
| `llama3.2:3b` | 2GB | âš¡âš¡âš¡ | â­â­â­ | å¿«é€Ÿåˆç­› (æ¨è) |
| `llama3.1:8b` | 5GB | âš¡âš¡ | â­â­â­â­ | å¹³è¡¡ |
| `qwen2.5:7b` | 4GB | âš¡âš¡ | â­â­â­â­ | ä¸­æ–‡ä»£ç  |
| `mistral:7b` | 4GB | âš¡âš¡ | â­â­â­â­â­ | é«˜è´¨é‡ |
| `gpt-3.5-turbo` | - | âš¡ | â­â­â­â­â­ | äº‘ç«¯å¤‡é€‰ |

## æ–‡ä»¶æ¸…å•

```
â”œâ”€â”€ ai_detector.py              # AI æ£€æµ‹æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ ai_scanner_integration.py   # Scanner é›†æˆæ¨¡å—
â”œâ”€â”€ test_ai_detector.py         # æµ‹è¯•è„šæœ¬
â””â”€â”€ AI_DETECTOR_README.md       # æœ¬æ–‡æ¡£
```

## æ•…éšœæ’é™¤

### Ollama è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ Ollama æœåŠ¡
curl http://localhost:11434/api/tags

# é‡å¯ Ollama
ollama serve
```

### æ¨¡å‹ä¸å­˜åœ¨

```bash
# åˆ—å‡ºå·²å®‰è£…æ¨¡å‹
ollama list

# æ‹‰å–æ¨¡å‹
ollama pull llama3.2:3b
```

### æ£€æµ‹ç»“æœä¸å‡†ç¡®

1. å°è¯•ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ (`llama3.1:8b`)
2. æ£€æŸ¥ä»£ç ä¸Šä¸‹æ–‡æ˜¯å¦å®Œæ•´
3. ä½¿ç”¨äº¤äº’å¼æµ‹è¯•è°ƒè¯•

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2026-01)

- åˆå§‹ç‰ˆæœ¬
- æ”¯æŒ Ollama/OpenAI/Mock åç«¯
- å¿«é€Ÿè§„åˆ™è¿‡æ»¤å™¨
- Few-shot + Chain of Thought æç¤º
- ç»“æœç¼“å­˜
